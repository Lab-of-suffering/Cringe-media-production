{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd320d06",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "1) Generating images\n",
    "2) Generating text images with empty background\n",
    "3) Combining images with texts using replicate\n",
    "4) Combining new images into a video using shot stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d5165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q transformers accelerate torch\n",
    "# !pip install -q diffusers==0.31.0 safetensors accelerate\n",
    "# !nvidia-smi || true\n",
    "# !pip install pillow\n",
    "# !pip install sacremoses\n",
    "# !pip install replicate\n",
    "\n",
    "# # Fonts\n",
    "# !sudo apt -y update >/dev/null\n",
    "# !sudo apt -y install fonts-dejavu fonts-freefont-ttf fonts-noto-core >/dev/null\n",
    "# !wget -q https://github.com/google/fonts/raw/main/ofl/lobster/Lobster-Regular.ttf -O /usr/share/fonts/truetype/lobster.ttf\n",
    "# !wget -q https://github.com/google/fonts/raw/main/ofl/montserrat/Montserrat-Bold.ttf -O /usr/share/fonts/truetype/montserrat-bold.ttf\n",
    "# !fc-cache -f\n",
    "\n",
    "# # Fonts\n",
    "# !apt-get -y update -qq\n",
    "# !apt-get -y install -qq fonts-dejavu fonts-dejavu-core fonts-dejavu-extra fonts-freefont-ttf fonts-noto-core\n",
    "# !fc-cache -f\n",
    "\n",
    "import re, torch, os, random, glob, unicodedata as ud\n",
    "import asyncio\n",
    "import replicate\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "from diffusers import StableDiffusionXLPipeline\n",
    "from IPython.display import display\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from pathlib import Path\n",
    "from uuid import UUID, uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f468f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE   = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE    = torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
    "W, H     = 512, 512\n",
    "LORA_DIR = \"\"\n",
    "WT_NAME  = \"pytorch_lora_weights.safetensors\"\n",
    "BASE     = \"Manojb/stable-diffusion-2-1-base\"\n",
    "\n",
    "ruen_tok = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")\n",
    "ruen_mt  = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\").to(DEVICE).eval()\n",
    "\n",
    "@torch.inference_mode()\n",
    "def ru2en(text: str) -> str:\n",
    "    enc = ruen_tok(text.strip(), return_tensors=\"pt\").to(DEVICE)\n",
    "    out = ruen_mt.generate(**enc, max_new_tokens=64)\n",
    "    return ruen_tok.batch_decode(out, skip_special_tokens=True)[0].strip()\n",
    "\n",
    "CYR = re.compile(r\"[А-Яа-яЁё]\")\n",
    "def to_english(s: str) -> str:\n",
    "    return ru2en(s) if CYR.search(s) else s.strip()\n",
    "\n",
    "q_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "q_tok = AutoTokenizer.from_pretrained(q_model_id)\n",
    "q_llm = AutoModelForCausalLM.from_pretrained(q_model_id, torch_dtype=DTYPE).to(DEVICE).eval()\n",
    "\n",
    "SYSTEM = (\n",
    "    \"You rewrite a short holiday/topic into three concise Stable Diffusion XL prompts for a festive POSTCARD.\\n\"\n",
    "    \"- Keep each line concrete and short (<= 48 words).\\n\"\n",
    "    \"- Focus on specific subjects and simple composition (what/where/background).\\n\"\n",
    "    \"- Allowed: pastel background, soft bokeh, glitter sparkles, glossy highlights, photomontage postcard style.\\n\"\n",
    "    \"- Must include: 'postcard, no text'.\\n\"\n",
    "    \"- FORBIDDEN: masterpiece, 8k, absurdres, by <artist>, nsfw, anatomy, camera brands, friends, family, group, people, girl, boy, man, woman\\n\"\n",
    "    \"- Avoid winter/snow/Christmas motifs unless the topic explicitly mentions them.\\n\"\n",
    "    \"- Output exactly three lines, no numbering.\"\n",
    ")\n",
    "\n",
    "EXAMPLES = (\n",
    "    \"Examples:\\n\"\n",
    "    \"Valentine's Day -> picture of two kittens sitting inside a big pink heart, sparkles and roses, pastel background, no text\\n\"\n",
    "    \"International Women's Day -> pink roses and satin ribbon arranged neatly, pastel gradient background, soft bokeh, postcard, no text\\n\"\n",
    "    \"Easter -> yellow chick emerging from decorated egg shell, surrounded by spring flowers, pastel pink and green background, glitter sparkles, glossy highlights, photomontage postcard style, no humans, no text\\n\"\n",
    "    \"Christmas -> white dove flying over red roses, glowing sunset, sparkles, high saturation, no text\\n\"\n",
    ")\n",
    "\n",
    "def normalize_topic(en_text: str) -> str:\n",
    "    t = en_text.strip().lower()\n",
    "    if t in {\"8 march\", \"march 8\", \"8th march\"}:\n",
    "        return \"International Women's Day\"\n",
    "    return en_text.strip()\n",
    "\n",
    "def build_chat_inputs(topic_en: str):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM + \"\\n\" + EXAMPLES},\n",
    "        {\"role\": \"user\",   \"content\": f\"Topic: {topic_en}\\nReturn 3 lines, one per prompt.\"}\n",
    "    ]\n",
    "\n",
    "    prompt_text = q_tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    enc = q_tok(prompt_text, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
    "    return enc\n",
    "\n",
    "BLACK = [\n",
    "    r\"\\bmasterpiece\\b\", r\"\\b8k\\b\", r\"\\babsurdres\\b\",\n",
    "    r\"\\b(anatomy|nsfw)\\b\", r\"\\bby\\s+[A-Z][a-z]+\\b\", r\"\\bdslr\\b\"\n",
    "]\n",
    "\n",
    "def sanitize_line(line: str, max_words=48) -> str:\n",
    "    t = line.strip()\n",
    "    t = re.sub(r\"^\\s*\\d+\\s*[\\.\\)\\-:]\\s*\", \"\", t)\n",
    "    for patt in BLACK:\n",
    "        t = re.sub(patt, \"\", t, flags=re.IGNORECASE)\n",
    "    t = re.sub(r\"\\s*,\\s*\", \", \", t)\n",
    "    t = re.sub(r\"(,\\s*){2,}\", \", \", t).strip(\" ,\")\n",
    "    low = t.lower()\n",
    "    if \"postcard\" not in low: t += \", postcard\"\n",
    "    if \"no text\" not in low:  t += \", no text\"\n",
    "    words = t.split()\n",
    "    if len(words) > max_words: t = \" \".join(words[:max_words])\n",
    "    return t\n",
    "\n",
    "@torch.inference_mode()\n",
    "def make_three_prompts(user_text: str, temperature=0.2) -> dict:\n",
    "    topic_en = normalize_topic(to_english(user_text))\n",
    "    enc = build_chat_inputs(topic_en)\n",
    "    out = q_llm.generate(\n",
    "        **enc, max_new_tokens=200, do_sample=True, temperature=temperature,\n",
    "        top_p=0.8, repetition_penalty=1.05,\n",
    "        eos_token_id=q_tok.eos_token_id, pad_token_id=q_tok.eos_token_id\n",
    "    )\n",
    "    raw = q_tok.decode(out[0, enc[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
    "    lines = [s.strip() for s in raw.splitlines() if s.strip()]\n",
    "    lines = lines[:3] if len(lines) >= 3 else (lines + [\"\"]*(3-len(lines)))\n",
    "    clean = [sanitize_line(l) if l else\n",
    "             \"festive postcard scene with fitting symbols, pastel background, soft bokeh, glitter sparkles, postcard, no text\"\n",
    "             for l in lines]\n",
    "    neg = \"text, letters, watermark, logo, low quality, blurry, jpeg artifacts, duplicates, extra limbs, extra heads, people, bad anatomy\"\n",
    "    return {\"topic_en\": topic_en, \"prompts\": clean, \"negative\": neg}\n",
    "\n",
    "\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    BASE, torch_dtype=torch.float16\n",
    ").to(DEVICE)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "\n",
    "pipe.enable_attention_slicing()\n",
    "pipe.enable_vae_slicing()\n",
    "pipe.enable_vae_tiling()\n",
    "\n",
    "# LoRA\n",
    "pipe.load_lora_weights(LORA_DIR, weight_name=WT_NAME)\n",
    "\n",
    "\n",
    "def gen(prompt: str, outfile: str, negative: str,\n",
    "        steps=24, cfg=6.2, w=512, h=512, seed=1234):\n",
    "    g = torch.Generator(device=DEVICE).manual_seed(seed)\n",
    "    image = pipe(\n",
    "        prompt=prompt, negative_prompt=negative,\n",
    "        num_inference_steps=steps, guidance_scale=cfg,\n",
    "        width=w, height=h, generator=g\n",
    "    ).images[0]\n",
    "    image.save(outfile)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098c3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images\n",
    "INPUT_PATH = \"../resources/\"\n",
    "user_text = \"Новый год\" # input()\n",
    "\n",
    "\n",
    "pack = make_three_prompts(user_text)\n",
    "print(\"EN topic:\", pack[\"topic_en\"])\n",
    "for i, p in enumerate(pack[\"prompts\"], 1):\n",
    "    print(f\"Prompt {i}: {p}\")\n",
    "print(\"NEG:\", pack[\"negative\"])\n",
    "\n",
    "imgs = []\n",
    "image_filenames = []\n",
    "for i, p in enumerate(pack[\"prompts\"], 1):\n",
    "    try:\n",
    "        file_name = INPUT_PATH + uuid4().hex + \".png\"\n",
    "        img = gen(p, file_name, negative=pack[\"negative\"], seed=1000+i)\n",
    "        image_filenames.append(file_name)\n",
    "        imgs.append(img); display(img)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00446740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texts\n",
    "\n",
    "MODEL_NAME = os.environ.get(\"SLOGAN_LLM\", \"Qwen/Qwen2.5-1.5B-Instruct\")\n",
    "K_OUT      = 5\n",
    "SEED       = 23\n",
    "BG_DEFAULT = \"transparent\"      # \"transparent\" | \"white\"\n",
    "PALETTE    = [(231,76,60),(46,204,113),(52,152,219),(155,89,182),(241,196,15),(20,20,20)]\n",
    "\n",
    "SYS = (\n",
    "    \"You output ultra-short keywords. \"\n",
    "    \"Language: {lang}. One variant per line, no numbering. \"\n",
    "    \"1 to {maxw} words. No punctuation, quotes, emoji, hashtags.\"\n",
    ")\n",
    "\n",
    "SAFE_FAMILIES = (\"DejaVuSans\", \"NotoSans\")\n",
    "\n",
    "random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "def collect_fonts() -> list[Path]:\n",
    "    roots = (\"/usr/share/fonts\", \"/usr/local/share/fonts\")\n",
    "    keep = []\n",
    "    for d in roots:\n",
    "        keep += [Path(p) for p in glob.glob(os.path.join(d, \"**\", \"DejaVuSans*.ttf\"), recursive=True)]\n",
    "        keep += [Path(p) for p in glob.glob(os.path.join(d, \"**\", \"NotoSans*.ttf\"),   recursive=True)]\n",
    "    order = {\"DejaVuSans.ttf\":0, \"DejaVuSans-Bold.ttf\":1, \"DejaVuSans-Oblique.ttf\":2,\n",
    "             \"NotoSans-Regular.ttf\":3, \"NotoSans-Bold.ttf\":4, \"NotoSans-Italic.ttf\":5}\n",
    "    keep = [p for p in keep if p.exists()]\n",
    "    keep.sort(key=lambda p: (order.get(p.name, 99), p.name))\n",
    "    return keep\n",
    "\n",
    "\n",
    "def font_supports_text(font_path: Path, text: str) -> bool:\n",
    "    try:\n",
    "        f = ImageFont.truetype(str(font_path), size=28)\n",
    "    except Exception:\n",
    "        return False\n",
    "    for ch in text:\n",
    "        if ch in \" -\":\n",
    "            continue\n",
    "        try:\n",
    "            bbox = f.getbbox(ch)\n",
    "        except Exception:\n",
    "            try:\n",
    "                w,h = f.getsize(ch); bbox = (0,0,w,h)\n",
    "            except Exception:\n",
    "                return False\n",
    "        if not bbox or (bbox[2]-bbox[0]) <= 0 or (bbox[3]-bbox[1]) <= 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def load_llm():\n",
    "    tok = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME, torch_dtype=DTYPE, device_map=\"auto\", trust_remote_code=True\n",
    "    )\n",
    "    return tok, model\n",
    "\n",
    "def detect_lang(text: str) -> str:\n",
    "    return \"ru\" if re.search(r\"[\\u0400-\\u04FF]\", text) else \"en\"\n",
    "\n",
    "def sanitize(text: str, lang: str) -> str:\n",
    "    t = ud.normalize(\"NFKC\", text)\n",
    "    t = t.replace(\"\\u00A0\", \" \").replace(\"\\u2009\", \" \").replace(\"\\u202F\", \" \")\n",
    "    t = re.sub(r\"[\\\"\"\"'«».,:;!?/\\\\()\\[\\]{}*_+=~^`|]\", \"\", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    allow = r\"[^\\u0400-\\u04FF0-9\\- ]\" if lang == \"ru\" else r\"[^A-Za-z0-9\\- ]\"\n",
    "    t = re.sub(allow, \"\", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    if re.search(r\"\\d{4}\", t):\n",
    "        t = re.sub(r\"\\d{4}\", \"\", t).strip()\n",
    "    return t\n",
    "\n",
    "def gen_phrases(topic: str, lang: str, k: int) -> list[str]:\n",
    "    tok, model = load_llm()\n",
    "    RX = re.compile(r\"^[\\u0400-\\u04FF0-9\\- ]{1,40}$\") if lang==\"ru\" else re.compile(r\"^[A-Za-z0-9\\- ]{1,40}$\")\n",
    "\n",
    "    examples = {\n",
    "        \"ru\": \"Примеры:\\nС Новым годом\\nС Рождеством\\nЗимняя сказка\\nТёплых праздников\",\n",
    "        \"en\": \"Examples:\\nMerry Christmas\\nHappy New Year\\nHoliday cheer\\nWarm wishes\",\n",
    "    }\n",
    "    script_rule = \"Use only Cyrillic letters (А-Я, а-я).\" if lang==\"ru\" else \"Use only Latin letters (A–Z, a–z).\"\n",
    "\n",
    "    def ask_one() -> str:\n",
    "        sys_prompt = (\n",
    "            f\"Generate ONE ultra-short greeting/tagline. Language: {lang}. \"\n",
    "            \"1–4 words. No quotes, punctuation, emoji, hashtags. \"\n",
    "            + script_rule + \"\\n\" + examples[lang]\n",
    "        )\n",
    "        user = f\"Topic: {topic}\\nReturn only the phrase on the first line.\"\n",
    "        if hasattr(tok, \"apply_chat_template\"):\n",
    "            prompt = tok.apply_chat_template(\n",
    "                [{\"role\":\"system\",\"content\":sys_prompt},\n",
    "                 {\"role\":\"user\",\"content\":user}],\n",
    "                tokenize=False, add_generation_prompt=True\n",
    "            )\n",
    "        else:\n",
    "            prompt = sys_prompt + \"\\n\" + user + \"\\nAssistant:\\n\"\n",
    "\n",
    "        enc = tok(prompt, return_tensors=\"pt\"); enc = {k:v.to(model.device) for k,v in enc.items()}\n",
    "        out = model.generate(**enc, max_new_tokens=48, temperature=0.6, top_p=0.85,\n",
    "                             do_sample=True, repetition_penalty=1.08,\n",
    "                             eos_token_id=getattr(tok,\"eos_token_id\",None))\n",
    "        new = out[0, enc[\"input_ids\"].shape[1]:]\n",
    "        raw = tok.decode(new, skip_special_tokens=True)\n",
    "        s = raw.splitlines()[0].strip() or re.split(r\"[,\\uFF0C;]+\", raw)[0].strip()\n",
    "        s = ud.normalize(\"NFKC\", s)\n",
    "        s = re.sub(r\"[\\\"\"\"'«».,:;!?/\\\\()\\[\\]{}*_+=~^`|]\", \"\", s)\n",
    "        s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "        s = re.sub(r\"[^\\u0400-\\u04FF0-9\\- ]\",\"\",s) if lang==\"ru\" else re.sub(r\"[^A-Za-z0-9\\- ]\",\"\",s)\n",
    "        s = re.sub(r\"\\s+\",\" \",s).strip()\n",
    "        return s\n",
    "\n",
    "    res, seen, tries = [], set(), 0\n",
    "    topic_norm = re.sub(r\"\\s+\",\" \", topic.lower()).strip()\n",
    "    while len(res) < k and tries < k*10:\n",
    "        tries += 1\n",
    "        s = ask_one()\n",
    "        if not s or not RX.match(s):\n",
    "            continue\n",
    "        if not (1 <= len(s.split()) <= 4):\n",
    "            continue\n",
    "        key = s.lower()\n",
    "        if key == topic_norm or key in {\"system\",\"assistant\",\"user\",\"topic\"}:\n",
    "            continue\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key); res.append(s)\n",
    "    return res\n",
    "\n",
    "\n",
    "def fit_font(font_path: Path, text: str, draw: ImageDraw.ImageDraw, w: int, h: int):\n",
    "    lo, hi, best = 14, 260, None\n",
    "    while lo <= hi:\n",
    "        mid = (lo + hi)//2\n",
    "        try:\n",
    "            f = ImageFont.truetype(str(font_path), size=mid)\n",
    "        except Exception:\n",
    "            f = ImageFont.load_default()\n",
    "        x0,y0,x1,y1 = draw.textbbox((0,0), text, font=f)\n",
    "        if (x1-x0) <= w and (y1-y0) <= h:\n",
    "            best = f; lo = mid + 1\n",
    "        else:\n",
    "            hi = mid - 1\n",
    "    return best or ImageFont.load_default()\n",
    "\n",
    "def render_phrase(text: str, font_path: Path, color=(20,20,20), bg=\"transparent\"):\n",
    "    fonts = collect_fonts()\n",
    "    use = next((p for p in fonts if p.name.endswith(\"Bold.ttf\")), fonts[0])\n",
    "\n",
    "    mode = \"RGBA\" if bg==\"transparent\" else \"RGB\"\n",
    "    img  = Image.new(mode, (W,H), (0,0,0,0) if mode==\"RGBA\" else (255,255,255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = fit_font(use, text, draw, W-60, H-40)\n",
    "    x0,y0,x1,y1 = draw.textbbox((0,0), text, font=font)\n",
    "    x,y = (W-(x1-x0))//2, (H-(y1-y0))//2\n",
    "    stroke = (0,0,0,200) if mode==\"RGBA\" else (0,0,0)\n",
    "    draw.text((x,y), text, font=font, fill=color, stroke_width=2, stroke_fill=stroke)\n",
    "\n",
    "    file_name = uuid4().hex\n",
    "    file_path = os.path.join(INPUT_PATH, file_name + '.png')\n",
    "    img.save(file_path)\n",
    "    return img, file_path\n",
    "\n",
    "\n",
    "# main function\n",
    "def generate_and_display(topic: str, lang: str=\"auto\", bg: str=BG_DEFAULT, k: int=K_OUT):\n",
    "    fonts = collect_fonts()\n",
    "    if not fonts:\n",
    "        raise SystemExit(\"No fonts found. Install DejaVu/Noto.\")\n",
    "    lang = detect_lang(topic) if lang==\"auto\" else lang\n",
    "\n",
    "    phrases = gen_phrases(topic, lang, k)\n",
    "    if len(phrases) < k:\n",
    "        need = k - len(phrases)\n",
    "        extra = gen_phrases(topic + \" variations\", lang, need)\n",
    "        for p in extra:\n",
    "            if p.lower() not in {x.lower() for x in phrases}:\n",
    "                phrases.append(p)\n",
    "            if len(phrases) == k:\n",
    "                break\n",
    "    if not phrases:\n",
    "        phrases = [sanitize(topic, lang)]\n",
    "\n",
    "    base = next((p for p in fonts if \"DejaVuSans\" in p.name), fonts[0])\n",
    "    alt  = next((p for p in fonts if \"NotoSans\"  in p.name), fonts[min(1, len(fonts)-1)])\n",
    "    font_pool = [base, alt] + random.sample(fonts, k=min(3, len(fonts)))\n",
    "\n",
    "    text_filenames = []\n",
    "    for t in phrases[:k]:\n",
    "        img, file_path = render_phrase(t, random.choice(font_pool), color=random.choice(PALETTE), bg=bg)\n",
    "        display(img)\n",
    "        text_filenames.append(file_path)\n",
    "    return text_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb42da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making empty images with text\n",
    "text_filenames = generate_and_display(user_text, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6761288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMBINATION_PROMPT = \"Add an inscription from the second image to the top or to the bottom of the first image. Do not add any extra text \" \\\n",
    "\"that is not on my images. You can move the text freely to the best location. The result should look like a card my grandmother might send me.\"\n",
    "\n",
    "#TODO: Change aspect_ratio\n",
    "async def add_text_to_image(text_image_path: str, \n",
    "                      main_image_path: str, \n",
    "                      output_dir: str = '../image_outputs',\n",
    "                      output_size: str = '1K', \n",
    "                      aspect_ratio: str = '1:1',\n",
    "                      save_locally: bool = True) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Combine one main image with one text image (async version).\n",
    "    Must have REPLICATE_API_TOKEN=... in the .env\n",
    "    \"\"\"\n",
    "\n",
    "    # Run file I/O and replicate API calls in executor to avoid blocking\n",
    "    loop = asyncio.get_event_loop()\n",
    "    \n",
    "    # Upload images to replicate to be able to use them\n",
    "    def upload_images():\n",
    "        with open(text_image_path, \"rb\") as file:\n",
    "            text_image = replicate.files.create(file)\n",
    "        with open(main_image_path, 'rb') as file:\n",
    "            generated_image = replicate.files.create(file)\n",
    "        return text_image, generated_image\n",
    "    \n",
    "    text_image, generated_image = await loop.run_in_executor(None, upload_images)\n",
    "\n",
    "    input_data = {\n",
    "        \"size\": output_size,\n",
    "        \"prompt\": COMBINATION_PROMPT, \n",
    "        \"aspect_ratio\": aspect_ratio,\n",
    "        \"image_input\": [generated_image.urls['get'], text_image.urls['get']]\n",
    "    }\n",
    "\n",
    "    # Run replicate.run in executor\n",
    "    def run_replicate():\n",
    "        return replicate.run(\"bytedance/seedream-4\", input=input_data)\n",
    "    \n",
    "    output = await loop.run_in_executor(None, run_replicate)\n",
    "\n",
    "    # Write the files to disk:\n",
    "    local_filename = \"\"\n",
    "    if save_locally:\n",
    "        def save_output():\n",
    "            for index, item in enumerate(output):\n",
    "                file_name = uuid4().hex\n",
    "                with open(os.path.join(output_dir, file_name + '.jpg'), \"wb\") as file:\n",
    "                    file.write(item.read())\n",
    "                    return file.name\n",
    "            return \"\"\n",
    "        \n",
    "        local_filename = await loop.run_in_executor(None, save_output)\n",
    "            \n",
    "    return str(output[0]), local_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649372c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will run for up to a couple of minutes\n",
    "results = await asyncio.gather(*[\n",
    "    add_text_to_image(text_filenames[i], image_filenames[i], output_dir=\"../image_outputs\") \n",
    "    for i in range(len(text_filenames))\n",
    "])\n",
    "\n",
    "# Unpack tuples into two separate lists\n",
    "images_with_text = [url for url, _ in results]\n",
    "images_with_text_paths = [path for _, path in results]\n",
    "\n",
    "print(f\"Generated {len(images_with_text)} images\")\n",
    "print(\"URLs:\", images_with_text)\n",
    "print(\"Local paths:\", images_with_text_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850af8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://replicate.delivery/xezq/84T4kLMzec3PcCP634DFdaqseBOH3BViJMfzqSfkzRm0bAzVB/tmpt48oksj1.jpg',\n",
       " 'https://replicate.delivery/xezq/kimVbGRzidKaH1c3Xh6AxDkM1dZjW0QDVhCgiCmZ6VepDYuKA/tmpj7womds5.jpg',\n",
       " 'https://replicate.delivery/xezq/chDiVJbKeQSEMSFe4IaeeHWyAKclwZXOeQ2LpNo702Cm9AmrC/tmpx0rq582q.jpg',\n",
       " 'https://replicate.delivery/xezq/e1XHxROiewrFQ0Kj7OznK18qMz4QTOS08eWC2sSH1hWIQg5qA/tmpob44khff.jpg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_with_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effb505b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 {\"success\":true,\"message\":\"Created\",\"response\":{\"message\":\"Render Successfully Queued\",\"id\":\"8ec53e29-1721-4685-88cc-c0afcf2df688\"}}\n"
     ]
    }
   ],
   "source": [
    "# Combining images into a video\n",
    "API_KEY = os.environ['SHOT_STACK_API_TOKEN']\n",
    "\n",
    "# for production use \"https://api.shotstack.io/v1/render\"\n",
    "url = \"https://api.shotstack.io/stage/render\"\n",
    "headers = {\n",
    "    \"x-api-key\": API_KEY,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "#TODO: Change aspect_ratio\n",
    "payload = {\n",
    "    \"timeline\": {\n",
    "        \"tracks\": [\n",
    "            {\n",
    "                \"clips\": [\n",
    "                    {\n",
    "                        \"asset\": {\"type\": \"image\", \"src\": images_with_text[0]},\n",
    "                        \"start\": 0,\n",
    "                        \"length\": 3,\n",
    "                        \"transition\": {\"out\": \"slideRight\"}\n",
    "                    },\n",
    "                    {\n",
    "                        \"asset\": {\"type\": \"image\", \"src\": images_with_text[1]},\n",
    "                        \"start\": 3,\n",
    "                        \"length\": 3,\n",
    "                        \"transition\": {\"in\": \"wipeLeft\", \"out\": \"fade\"}\n",
    "                    },\n",
    "                    {\n",
    "                        \"asset\": {\"type\": \"image\", \"src\": images_with_text[2]},\n",
    "                        \"start\": 6,\n",
    "                        \"length\": 3,\n",
    "                        \"transition\": {\"in\": \"slideUp\", \"out\": \"slideDown\"}\n",
    "                    },\n",
    "\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"output\": {\"format\": \"mp4\", \"resolution\": \"hd\", \"aspectRatio\": \"1:1\"}\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "print(response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f5819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': True, 'message': 'OK', 'response': {'id': '8ec53e29-1721-4685-88cc-c0afcf2df688', 'owner': '1mj5p7ly7k', 'plan': 'freeTrial', 'status': 'done', 'error': '', 'duration': 12, 'billable': 12, 'renderTime': 3708.53, 'url': 'https://shotstack-api-stage-output.s3-ap-southeast-2.amazonaws.com/1mj5p7ly7k/8ec53e29-1721-4685-88cc-c0afcf2df688.mp4', 'poster': None, 'thumbnail': None, 'data': {'output': {'format': 'mp4', 'resolution': 'hd', 'aspectRatio': '4:3'}, 'timeline': {'tracks': [{'clips': [{'start': 0, 'length': 3, 'asset': {'type': 'image', 'src': 'https://replicate.delivery/xezq/84T4kLMzec3PcCP634DFdaqseBOH3BViJMfzqSfkzRm0bAzVB/tmpt48oksj1.jpg'}, 'transition': {'out': 'slideRight'}}, {'start': 3, 'length': 3, 'asset': {'type': 'image', 'src': 'https://replicate.delivery/xezq/kimVbGRzidKaH1c3Xh6AxDkM1dZjW0QDVhCgiCmZ6VepDYuKA/tmpj7womds5.jpg'}, 'transition': {'in': 'wipeLeft', 'out': 'fade'}}, {'start': 6, 'length': 3, 'asset': {'type': 'image', 'src': 'https://replicate.delivery/xezq/chDiVJbKeQSEMSFe4IaeeHWyAKclwZXOeQ2LpNo702Cm9AmrC/tmpx0rq582q.jpg'}, 'transition': {'in': 'slideUp', 'out': 'slideDown'}}, {'start': 9, 'length': 3, 'asset': {'type': 'image', 'src': 'https://replicate.delivery/xezq/e1XHxROiewrFQ0Kj7OznK18qMz4QTOS08eWC2sSH1hWIQg5qA/tmpob44khff.jpg'}, 'transition': {'in': 'fade'}}]}]}}, 'created': '2025-10-07T17:38:26.272Z', 'updated': '2025-10-07T17:38:32.662Z'}}\n",
      "Video url: https://shotstack-api-stage-output.s3-ap-southeast-2.amazonaws.com/1mj5p7ly7k/8ec53e29-1721-4685-88cc-c0afcf2df688.mp4\n"
     ]
    }
   ],
   "source": [
    "# Wait a bit before running\n",
    "RENDER_ID = json.loads(response.text)['response']['id']\n",
    "\n",
    "# for production use f\"https://api.shotstack.io/v1/render/{RENDER_ID}\"\n",
    "url = \"https://api.shotstack.io/stage/render\"\n",
    "r = requests.get(url + f\"/{RENDER_ID}\", headers=headers)\n",
    "\n",
    "print(r.json())\n",
    "print(\"Video url:\", r.json()['response']['url'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
